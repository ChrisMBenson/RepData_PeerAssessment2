install.packages("rpart")
install.packages("ggplot2")
?kmenas
?kmeans
install.packages("gbm")
install.packages("manipulate")
install.packages("KernSmooth")
library("swirl")
swirl()
library("Swirl")
library("swirl")
swirl()
x
x[1:10]
x[is.na(x)]
x[!is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x>0]
x[!isna(x) & x > 0]
x[!is.na(x) & x > 0]
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2,-10)]
x[-c(2,10)]
vect <- c(foo=11, bar=2, norf=NA)
vect
names(vect)
vect2 <- c(11,2,NA)
names(vect2) <- c("foo","bar","norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo","bar")]
0
exit
bye()
swirl()
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4,5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
my_matrix2 <- (1:20,4,5)
my_matrix2 <- matrix(1:20,4,5)
identical(my_matrix, my_matrix2)
patients <- c("Bill","Gina","Kelly","Sean")
cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames <- c("patient","age","weight","bp","rating", "test")
colnames(my_data)
colnames(my_data) <- cnames
my_data
TRUE == TRUE
(FALSE == TRUE) == TRUE
(FALSE == TRUE) == FALSE
6 == 7
6 < 7
10 <= 10
5 != 7
!(5 = 7)
!(5 == 7)
FALSE & FALSE
TRUE & C(TRUE,TRUE, TRUE)
TRUE & c(TRUE,TRUE, TRUE)
TRUE & c(TRUE, FALSE, FALSE)
c(TRUE, TRUE, TRUE) & c(FALSE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
isTRUE(6>4)
identical('twins', 'twins')
xor(5==6, !FALSE)
ints <- sample(10)
ints
ints >5
which(ints > 7)
any(ints < 0)
all(ints > 0)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
library("ggplot2", lib.loc="~/R/win-library/3.1")
qplot(Wind, Ozone, data = airquality, geom = "smooth")
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
library(kernlab)
install.packages("kernlab")
library(kernlab)
library(kernlab)
data(spam)
set.seed(3435)
trainIndicator <- rbinom(4601, size = 1, prob = 0.5)
table(trainIndicator)
trianSpam = spam[trainIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]
names(trainSpam)
names(trianSpam)
head(trianSpam)
table(trianSpam$type)
plot(log10(trianSpam$capitalAve + 1) ~ trianSpam$type)
plot(log10(trianSpam[,1:4] + 1))
hCluster <- hclust(dist(t(trianSpam[,1:57])))
plot(hCluster)
hClusterUpdated = hclust(dist(t(log10(trainSpam[, 1:55] + 1))))
plot(hClusterUpdated)
hClusterUpdated = hclust(dist(t(log10(trainSpam[, 1:55] + 1)))
)
hClusterUpdated = hclust(dist(t(log10(trianSpam[, 1:55] + 1))))
plot(hClusterUpdated)
trianSpam$numType = as.numeric(trianSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55) {
lmFormula = reformulate(names(triinSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trianSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
trianSpam$numType = as.numeric(trianSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55) {
lmFormula = reformulate(names(trianSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trianSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
trianSpam$numType = as.numeric(trianSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55) {
lmFormula = reformulate(names(trianSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trianSpam)
cvError[i] = cv.glm(trianSpam, glmFit, costFunction, 2)$delta[2]
}
trianSpam$numType = as.numeric(trianSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55) {
lmFormula = reformulate(names(trianSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trianSpam)
cvError[i] = cv.glm(trianSpam, glmFit, costFunction, 2)$delta[2]
}
names(trianSpam)[which.min(cvError)]
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trianSpam)
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.5] = "spam"
table(predictedSpam, testSpam$type)
(61 + 458)/(1346 + 458 + 61 + 449)
df <- read.csv("~/R/Automobile.csv", na.strings="?")
# Multiple Linear Regression Example
mod <- lm(price ~ make + body_style + engine_size + horsepower + highway_mpg, data=df)
summary(mod) # show results
# Other useful functions
coefficients(mod) # model coefficients
confint(mod, level=0.95) # CIs for model parameters
fitted(mod) # predicted values
residuals(mod) # residuals
anova(mod) # anova table
vcov(mod) # covariance matrix for model parameters
influence(mod) # regression diagnostics
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(mod)
make = "nissan"
body_style = "sedan"
engine_size = 140
horsepower = 100
highway_mpg = 25
newCar <- data.frame(make, body_style, engine_size, horsepower, highway_mpg)
predict(mod, newCar, interval = "prediction")
install.packages("B2Z")
# set the url path for the download
fileUrl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
#set the working directory
setwd("~/R/RepData_PeerAssessment2")
# set up some working variables. These can be changed depending on your requirements
workingDir = getwd()
dataDir = "data"
zipFile = "data/StormData.bz2"
# create a data directory if one does not exist directory
if (!file.exists(dataDir)){
dir.create(file.path(workingDir, dataDir))
}
# This setting is used to for https connections. Windows machine no curl installed
setInternet2(use = TRUE) #This needs to be set to support https. Could not use curl as not installed
if (!file.exists(zipFile)){
# download into the data directory
download.file(fileUrl, zipFile, method = "auto")
}
# get the name of the first file in the zip archive
fileName = unzip(zipFile, list=TRUE)$Name[1]
# unzip the file to the data directory
unzip(zipFile, files=fileName, exdir=dataDir, overwrite=TRUE)
# create dataFile which is full path to the extracted file
dataFile = file.path(dataDir, fileName)
# load the csv in data frame
stormData <- read.csv(dataFile, as.is=TRUE)
# set the url path for the download
fileUrl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
#set the working directory
setwd("~/R/RepData_PeerAssessment2")
# set up some working variables. These can be changed depending on your requirements
workingDir = getwd()
dataDir = "data"
fileName = "data/StormData.csv.bz2"
# create a data directory if one does not exist directory
if (!file.exists(dataDir)){
dir.create(file.path(workingDir, dataDir))
}
# This setting is used to for https connections. Windows machine no curl installed
setInternet2(use = TRUE) #This needs to be set to support https. Could not use curl as not installed
if (!file.exists(fileName)){
# download into the data directory
download.file(fileUrl, fileName, method = "auto")
}
# load the csv in data frame
stormData <- read.csv(fileName, as.is=TRUE)
head(stormData)
names(stormData)
str(stormData)
stormData[,c("EVTYPE")] <- toupper(stormData[,c("EVTYPE")])
stormData[, EVTYPE]
stormData[, "EVTYPE"]
View(stormData)
sessioninfo()
sessionInfo()
install.packages("curl")
curl
library(curl)
